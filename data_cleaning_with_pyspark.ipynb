{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "data cleaning with pyspark.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNyJ6tpmmifPAS+Nfgwqhj0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lau-Jr/data-engineering-dump/blob/main/data_cleaning_with_pyspark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#defining schema"
      ],
      "metadata": {
        "id": "MWG-E_aQDxAS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the pyspark.sql.types library\n",
        "from  pyspark.sql.types import *\n",
        "\n",
        "# Define a new schema using the StructType method\n",
        "people_schema = StructType([\n",
        "  # Define a StructField for each field\n",
        "  StructField('name', StringType(), False),\n",
        "  StructField('Age', IntegerType(), False),\n",
        "  StructField('City', StringType(), False)\n",
        "])"
      ],
      "metadata": {
        "id": "K3FRB2WsDziq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "XZzxZq3sDw5H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#lazy proceesing and immutability "
      ],
      "metadata": {
        "id": "WbDEna1eF0OP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aa_dfw_df = aa_dfw_df.withColumn('airport', F.lower(aa_dfw_df['Destination Airport']))\n",
        "\n",
        "# Drop the Destination Airport column\n",
        "aa_dfw_df = aa_dfw_df.drop(aa_dfw_df['Destination Airport'])\n",
        "\n",
        "# Show the DataFrame\n",
        "print(aa_dfw_df.show())"
      ],
      "metadata": {
        "id": "3gSnH965F5kI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Saving Data in Parquet Format"
      ],
      "metadata": {
        "id": "SkUG5BRlKeCC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# View the row count of df1 and df2\n",
        "print(\"df1 Count: %d\" % df1.count())\n",
        "print(\"df2 Count: %d\" % df2.count())\n",
        "\n",
        "# Combine the DataFrames into one\n",
        "df3 = df1.union(df2)\n",
        "\n",
        "# Save the df3 DataFrame in Parquet format\n",
        "df3.write.parquet('AA_DFW_ALL.parquet', mode='overwrite')\n",
        "\n",
        "# Read the Parquet file into a new DataFrame and run a count\n",
        "print(spark.read.parquet('AA_DFW_ALL.parquet').count())"
      ],
      "metadata": {
        "id": "ntAQFSx3KjQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#SQL and Parquet"
      ],
      "metadata": {
        "id": "G6V_Wz2vK_xY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the Parquet file into flights_df\n",
        "flights_df = spark.read.parquet('AA_DFW_ALL.parquet')\n",
        "\n",
        "# Register the temp table\n",
        "flights_df.createOrReplaceTempView('flights')\n",
        "\n",
        "# Run a SQL query of the average flight duration\n",
        "avg_duration = spark.sql('SELECT avg(flight_duration) from flights').collect()[0]\n",
        "print('The average flight time is: %d' % avg_duration)"
      ],
      "metadata": {
        "id": "EKcZmfh4LCY_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}