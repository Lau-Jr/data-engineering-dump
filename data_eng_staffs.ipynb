{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "data eng staffs.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOSe3t0St070Mn/Q9EX5+W6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lau-Jr/data-engineering-dump/blob/main/data_eng_staffs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tpVHMT400eWH"
      },
      "outputs": [],
      "source": [
        "# Function to extract table to a pandas DataFrame\n",
        "def extract_table_to_pandas(tablename, db_engine):\n",
        "    query = \"SELECT * FROM {}\".format(tablename)\n",
        "    return pd.read_sql(query, db_engine)\n",
        "\n",
        "# Connect to the database using the connection URI\n",
        "connection_uri = \"postgresql://repl:password@localhost:5432/pagila\" \n",
        "db_engine = sqlalchemy.create_engine(connection_uri)\n",
        "\n",
        "# Extract the film table into a pandas DataFrame\n",
        "extract_table_to_pandas(\"film\", db_engine)\n",
        "\n",
        "# Extract the customer table into a pandas DataFrame\n",
        "extract_table_to_pandas(\"customer\", db_engine)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "# Fetch the Hackernews post\n",
        "resp = requests.get(\"https://hacker-news.firebaseio.com/v0/item/16222426.json\")\n",
        "\n",
        "# Print the response parsed as JSON\n",
        "print(resp.json())####status_code\n",
        "\n",
        "# Assign the score of the test to post_score\n",
        "post_score = resp.json()[\"score\"]\n",
        "print(post_score)"
      ],
      "metadata": {
        "id": "fQ1MaW4-074J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import requests"
      ],
      "metadata": {
        "id": "fDVCu3dD3LBk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resp = requests.get(\"https://hacker-news.firebaseio.com/v0/item/16222426.json\")\n",
        "resp.json()\n",
        "df = pd.read_csv(\"/content/sample_data/california_housing_test.csv\")"
      ],
      "metadata": {
        "id": "W0-1nDxb3Yq9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# spliting data in panda\n",
        "# df.assign()"
      ],
      "metadata": {
        "id": "1Q1LEcx74BGm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import SparkSession from pyspark.sql\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Create my_spark\n",
        "spark = SparkSession.builder.getOrCreate()\n",
        "\n",
        "# Print my_spark\n",
        "print(spark)"
      ],
      "metadata": {
        "id": "-SPqQxZWCZM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the tables in the catalog\n",
        "print(spark.catalog.listTables())"
      ],
      "metadata": {
        "id": "0W7cdvXNENKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Don't change this query\n",
        "query = \"FROM flights SELECT * LIMIT 10\"\n",
        "\n",
        "# Get the first 10 rows of flights\n",
        "flights10 = spark.sql(query)\n",
        "\n",
        "# Show the results\n",
        "flights10.show()"
      ],
      "metadata": {
        "id": "7lbhaTqSGVTL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Don't change this query\n",
        "query = \"SELECT origin, dest, COUNT(*) as N FROM flights GROUP BY origin, dest\"\n",
        "\n",
        "# Run the query\n",
        "flight_counts = spark.sql(query)\n",
        "\n",
        "# Convert the results to a pandas DataFrame\n",
        "pd_counts = flight_counts.toPandas()\n",
        "\n",
        "# Print the head of pd_counts\n",
        "print(pd_counts)"
      ],
      "metadata": {
        "id": "LCVB_k22Nb0Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create pd_temp\n",
        "pd_temp = pd.DataFrame(np.random.random(10))\n",
        "\n",
        "# Create spark_temp from pd_temp\n",
        "spark_temp = spark.createDataFrame(pd_temp)\n",
        "\n",
        "# Examine the tables in the catalog\n",
        "print(spark.catalog.listTables())\n",
        "\n",
        "# Add spark_temp to the catalog\n",
        "spark_temp.createTempView('temp')\n",
        "\n",
        "# Examine the tables in the catalog again\n",
        "print(spark.catalog.listTables())"
      ],
      "metadata": {
        "id": "_Xbnmh87SF_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Don't change this file path\n",
        "file_path = \"/usr/local/share/datasets/airports.csv\"\n",
        "\n",
        "# Read in the airports data\n",
        "airports = spark.read.csv(file_path, header=True)\n",
        "\n",
        "# Show the data\n",
        "airports.show()"
      ],
      "metadata": {
        "id": "_uJDPGdWUdBR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the DataFrame flights\n",
        "flights = spark.table('flights')\n",
        "\n",
        "# Show the head\n",
        "flights.show()\n",
        "\n",
        "# Add duration_hrs\n",
        "flights = flights.withColumn('duration_hrs',flights.air_time / 60)\n",
        "flights.show()"
      ],
      "metadata": {
        "id": "yNBAkk7Pet9w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter flights by passing a string\n",
        "long_flights1 = flights.filter(\"distance > 1000\")\n",
        "\n",
        "# Filter flights by passing a column of boolean values\n",
        "long_flights2 = flights.filter(flights.distance > 1000)\n",
        "\n",
        "# Print the data to check they're equal\n",
        "long_flights1.show()\n",
        "long_flights2.show()"
      ],
      "metadata": {
        "id": "GKhT5xd4h61Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# spliting col\n",
        "# Get the rental rate column as a string\n",
        "rental_rate_str = film_df.rental_rate.astype(str)\n",
        "\n",
        "# Split up and expand the column\n",
        "rental_rate_expanded = rental_rate_str.str.split(\".\", expand=True)\n",
        "\n",
        "# Assign the columns to film_df\n",
        "film_df = film_df.assign(\n",
        "    rental_rate_dollar=rental_rate_expanded[0],\n",
        "    rental_rate_cents=rental_rate_expanded[1],\n",
        ")\n",
        "\n",
        "print(film_df.head())"
      ],
      "metadata": {
        "id": "J192KKP8i1Rz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# geting data to spark_df\n",
        "spark.read.jdbc(\"jdbc:postgresql://localhost:5432/pagila\",\n",
        "                \"customer\",\n",
        "                {\"user\":\"repl\",\"password\":\"password\"})"
      ],
      "metadata": {
        "id": "EgBMGAigjJWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# groupby spark_df\n",
        "# Use groupBy and mean to aggregate the column\n",
        "ratings_per_film_df = rating_df.groupBy('film_id').mean('rating')\n",
        "\n",
        "# Join the tables using the film_id column\n",
        "film_df_with_ratings = film_df.join(\n",
        "    ratings_per_film_df,\n",
        "    film_df.film_id==rating_df.film_id\n",
        ")\n",
        "\n",
        "# Show the 5 first results\n",
        "print(film_df_with_ratings.show(5))"
      ],
      "metadata": {
        "id": "BAzol2R-kESI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}